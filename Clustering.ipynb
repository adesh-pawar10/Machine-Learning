{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a2ea5a-829a-406b-98df-177d4f502573",
   "metadata": {},
   "source": [
    "<h1 style = \"color : dodgerblue\"> Clustering </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39f888-fe41-4ef6-92ee-316a93d52dbc",
   "metadata": {},
   "source": [
    "* Clustering is an unsupervised machine learning technique that involves grouping similar data points together into clusters.\n",
    "\n",
    "* Unlike supervised learning, where we have labeled data to train a model, clustering works with unlabeled data, discovering hidden patterns and structures within the data.\n",
    "\n",
    "* Clustering is a type of unsupervised learning in machine learning that involves grouping a set of objects in such a way that objects in the same group (or cluster) are more similar to each other than to those in other groups.\n",
    "\n",
    "* It helps to identify underlying patterns or natural groupings within data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5ec0c-ff04-4b8a-98e6-be973a5a55fc",
   "metadata": {},
   "source": [
    "<h2 style = \"color : DeepSkyBlue\"> Key Concepts: </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbccee3-1ecc-4665-9aa5-990c0039aec2",
   "metadata": {},
   "source": [
    "<b style = \"color : orangered\"> 1. Similarity: </b> The key to clustering is defining how similar two data points are. This is often measured using distance metrics like Euclidean distance, Manhattan distance, or cosine similarity.\n",
    "\n",
    "<b style = \"color : orangered\"> 2. Cluster: </b> A group of data points that are more similar to each other than to points in other clusters.\n",
    "\n",
    "<b style = \"color : orangered\"> 3. Centroid: </b> The central point of a cluster, often calculated as the mean of all data points in the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1d462-2d3a-4f45-86ff-f89d57b3b2a7",
   "metadata": {},
   "source": [
    "<h2 style = \"color : DeepSkyBlue\"> Types of Clustering Algorithms: </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e4fc5-70a9-4e8e-88b9-293a30a6bc72",
   "metadata": {},
   "source": [
    "<h3 style = \"color : CadetBlue\"> 1. Partition-Based Clustering: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919244f-7dee-4acd-b9dc-43277876ed9b",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li style = \"color : orangered\"><b>K-Means Clustering:</b></li>\n",
    "    One of the most popular algorithms, it aims to partition data into K clusters, with each data point assigned to the nearest centroid.\n",
    "  <li style = \"color : orangered\"><b>K-Medoids Clustering:</b></li>\n",
    "    Similar to K-Means, but uses medoids (actual data points) as cluster centers instead of means.\n",
    "</ul>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5e2ef-baa3-4add-8a6d-750381ed4e39",
   "metadata": {},
   "source": [
    "<h3 style = \"color : CadetBlue\"> 2. Hierarchical Clustering: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af54db-7ed3-40e3-9fef-52ddadaf097a",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li style = \"color : orangered\"><b>Agglomerative Hierarchical Clustering:</b></li>\n",
    "    Starts with each data point as a single cluster and merges the closest pairs of clusters iteratively until a single cluster remains.\n",
    "  <li style = \"color : orangered\"><b>Divisive Hierarchical Clustering:</b></li>\n",
    "    Starts with all data points in one cluster and recursively splits it into smaller clusters based on similarity.   \n",
    "</ul>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466b650e-0cac-49c9-bbe7-b38f5c7b1bda",
   "metadata": {},
   "source": [
    "<h3 style = \"color : CadetBlue\"> 3. Density-Based Clustering: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b88a47-e1b2-4742-aab7-5568ac726149",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li style = \"color : orangered\"><b>DBSCAN (Density-Based Spatial Clustering of Applications with Noise):</b></li>\n",
    "    Groups together points that are closely packed together (high density) and separates clusters that are well-separated from low-density regions.\n",
    "</ul>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f7948-068f-47da-8bcd-78e6a8ce6595",
   "metadata": {},
   "source": [
    "<h3 style = \"color : CadetBlue\"> 4. Distribution-Based Clustering: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8ecfb-9d38-4819-a5de-ea88b1f5c8bd",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li style = \"color : orangered\"><b>Gaussian Mixture Models (GMM):</b></li>\n",
    "    Assumes that the data is generated from a mixture of Gaussian distributions, and each cluster corresponds to a component of the mixture.\n",
    "</ul>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56401d12-d6c7-401f-9a4e-59c9c08e4f4a",
   "metadata": {},
   "source": [
    "<h2 style = \"color : DeepSkyBlue\"> Applications of Clustering: </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aefad6-e823-4dc2-93a7-3007326b0e3d",
   "metadata": {},
   "source": [
    "<b style = \"color : orangered\"> 1. Customer Segmentation: </b> Grouping customers based on their purchasing behavior, demographics, or other characteristics to tailor marketing strategies.\n",
    "\n",
    "<b style = \"color : orangered\"> 2. Image Segmentation: </b> Dividing images into meaningful regions, such as objects or backgrounds.\n",
    "\n",
    "<b style = \"color : orangered\"> 3. Document Clustering: </b> Grouping similar documents together for information retrieval or topic modeling.\n",
    "\n",
    "<b style = \"color : orangered\"> 4. Anomaly Detection: </b> Identifying outliers or anomalies in data that deviate significantly from normal patterns.\n",
    "\n",
    "<b style = \"color : orangered\"> 5. Biological Data Analysis: </b> Clustering genes or proteins based on their similarity to discover functional relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a042d-bde4-4911-9de0-d0fa66c3d310",
   "metadata": {},
   "source": [
    "<h2 style = \"color : DeepSkyBlue\"> Choosing the Right Clustering Algorithm: </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb008b-62c7-4f46-9ee4-7b950dd3b630",
   "metadata": {},
   "source": [
    "<h3 style = \"color : CadetBlue\"> The choice of clustering algorithm depends on various factors, including: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa270d0-1ea2-4553-96f5-321f7d370e8e",
   "metadata": {},
   "source": [
    "<b style = \"color : orangered\"> 1. Number of clusters: </b> If you know the number of clusters beforehand, K-Means or K-Medoids might be suitable.\n",
    "\n",
    "<b style = \"color : orangered\"> 2. Cluster shape: </b> If clusters are spherical, K-Means works well, but for irregularly shaped clusters, DBSCAN or hierarchical clustering might be more appropriate.\n",
    "\n",
    "<b style = \"color : orangered\"> 3. Noise and outliers: </b> DBSCAN is robust to noise and outliers.\n",
    "\n",
    "<b style = \"color : orangered\"> 4. Data distribution: </b> Gaussian Mixture Models are well-suited for data that follows a Gaussian distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
